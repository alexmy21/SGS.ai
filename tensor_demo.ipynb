{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CortexTensorDemo:\n",
    "    def __init__(self, n_basis=10, m_registers=8, b_bits=4, tau=0.6):\n",
    "        self.n_basis = n_basis\n",
    "        self.m = m_registers\n",
    "        self.b = b_bits\n",
    "        self.tau = tau\n",
    "        \n",
    "        # Initialize basis tensor: [n_basis, m, b] - binary HLLSets\n",
    "        self.basis_tensor = torch.bernoulli(torch.ones(n_basis, m_registers, b_bits) * 0.3)\n",
    "        \n",
    "        # Initialize content store (simulated)\n",
    "        self.content_store = {}\n",
    "        \n",
    "    def compute_id(self, tensor):\n",
    "        \"\"\"Compute content-addressable ID from tensor\"\"\"\n",
    "        tensor_bytes = tensor.numpy().tobytes()\n",
    "        return hashlib.sha256(tensor_bytes).hexdigest()[:16]\n",
    "    \n",
    "    def optimal_cover(self, hllset, top_k=3):\n",
    "        \"\"\"Find optimal cover of hllset by basis elements\"\"\"\n",
    "        # Compute similarities with all basis elements\n",
    "        similarities = []\n",
    "        for i in range(self.n_basis):\n",
    "            basis_vec = self.basis_tensor[i].flatten()\n",
    "            input_vec = hllset.flatten()\n",
    "            sim = torch.dot(input_vec, basis_vec) / (torch.norm(input_vec) * torch.norm(basis_vec) + 1e-8)\n",
    "            similarities.append(sim)\n",
    "        \n",
    "        similarities = torch.tensor(similarities)\n",
    "        \n",
    "        # Select top_k most similar basis elements\n",
    "        _, indices = torch.topk(similarities, top_k)\n",
    "        \n",
    "        # Create sparse i-context vector\n",
    "        i_context = torch.zeros(self.n_basis)\n",
    "        i_context[indices] = 1.0\n",
    "        \n",
    "        return i_context\n",
    "    \n",
    "    def create_edge_hllset(self, i_context_a, i_context_b):\n",
    "        \"\"\"Create Edge_HLLSet from intersection of i-contexts\"\"\"\n",
    "        # Intersection of basis elements\n",
    "        intersection_mask = (i_context_a * i_context_b) > 0\n",
    "        \n",
    "        if intersection_mask.sum() == 0:\n",
    "            return None\n",
    "            \n",
    "        # Union of intersecting basis elements\n",
    "        intersecting_basis = self.basis_tensor[intersection_mask]  # [k, m, b]\n",
    "        edge_hllset = torch.clamp(intersecting_basis.sum(dim=0), 0, 1)  # Bitwise OR\n",
    "        \n",
    "        return edge_hllset\n",
    "    \n",
    "    def build_context_tensor(self, input_hllsets):\n",
    "        \"\"\"Build context tensor from input HLLSets\"\"\"\n",
    "        context_vectors = []\n",
    "        \n",
    "        for hllset in input_hllsets:\n",
    "            i_context = self.optimal_cover(hllset)\n",
    "            context_vectors.append(i_context)\n",
    "            \n",
    "        return torch.stack(context_vectors)  # [V, n_basis]\n",
    "    \n",
    "    def compute_similarity_matrix(self, context_tensor):\n",
    "        \"\"\"Compute similarity matrix from context tensor\"\"\"\n",
    "        # Normalize context vectors\n",
    "        context_norm = F.normalize(context_tensor, p=2, dim=1)\n",
    "        \n",
    "        # Similarity matrix\n",
    "        similarity = torch.mm(context_norm, context_norm.T)\n",
    "        \n",
    "        return similarity\n",
    "    \n",
    "    def build_edge_tensor(self, context_tensor, similarity_matrix):\n",
    "        \"\"\"Build edge tensor from context tensor and similarities\"\"\"\n",
    "        V = context_tensor.shape[0]\n",
    "        edge_tensor = torch.zeros(V, V, 4)  # [edge_hllset_id, tau, rho, phi_hash]\n",
    "        \n",
    "        for i in range(V):\n",
    "            for j in range(i+1, V):\n",
    "                if similarity_matrix[i, j] >= self.tau:\n",
    "                    # Create edge\n",
    "                    edge_hllset = self.create_edge_hllset(context_tensor[i], context_tensor[j])\n",
    "                    \n",
    "                    if edge_hllset is not None:\n",
    "                        edge_id = self.compute_id(edge_hllset)\n",
    "                        edge_tensor[i, j, 0] = float(int(edge_id, 16) % 10000)  # Simulated ID\n",
    "                        edge_tensor[i, j, 1] = similarity_matrix[i, j]  # tau\n",
    "                        edge_tensor[i, j, 2] = 1 - similarity_matrix[i, j]  # rho\n",
    "                        edge_tensor[i, j, 3] = float(hash((i, j)) % 10000)  # phi hash\n",
    "                        \n",
    "                        # Store in content store\n",
    "                        self.content_store[edge_id] = edge_hllset\n",
    "        \n",
    "        return edge_tensor\n",
    "    \n",
    "    def abstract_layer(self, context_tensor, edge_tensor):\n",
    "        \"\"\"Create next layer context tensor from edges\"\"\"\n",
    "        V = context_tensor.shape[0]\n",
    "        new_context_vectors = []\n",
    "        \n",
    "        for i in range(V):\n",
    "            for j in range(i+1, V):\n",
    "                if edge_tensor[i, j, 0] > 0:  # Valid edge\n",
    "                    edge_id = str(int(edge_tensor[i, j, 0]))\n",
    "                    edge_hllset = self.content_store.get(edge_id)\n",
    "                    \n",
    "                    if edge_hllset is not None:\n",
    "                        # Compute i-context for the Edge_HLLSet\n",
    "                        edge_i_context = self.optimal_cover(edge_hllset)\n",
    "                        new_context_vectors.append(edge_i_context)\n",
    "        \n",
    "        if len(new_context_vectors) == 0:\n",
    "            return None\n",
    "            \n",
    "        return torch.stack(new_context_vectors)\n",
    "    \n",
    "    def cortex_transformation(self, input_hllsets, num_layers=3):\n",
    "        \"\"\"Complete Cortex transformation pipeline\"\"\"\n",
    "        print(\"=== Cortex Tensor Demo ===\\n\")\n",
    "        \n",
    "        # Store all layers\n",
    "        layers = []\n",
    "        \n",
    "        # Layer 0: Process input HLLSets\n",
    "        print(f\"Layer 0: Processing {len(input_hllsets)} input HLLSets\")\n",
    "        context_tensor_0 = self.build_context_tensor(input_hllsets)\n",
    "        similarity_0 = self.compute_similarity_matrix(context_tensor_0)\n",
    "        edge_tensor_0 = self.build_edge_tensor(context_tensor_0, similarity_0)\n",
    "        \n",
    "        layers.append({\n",
    "            'context': context_tensor_0,\n",
    "            'similarity': similarity_0,\n",
    "            'edges': edge_tensor_0\n",
    "        })\n",
    "        \n",
    "        print(f\"  Context tensor shape: {context_tensor_0.shape}\")\n",
    "        print(f\"  Non-zero edges: {(edge_tensor_0[:, :, 0] > 0).sum().item()}\")\n",
    "        \n",
    "        # Build higher layers\n",
    "        current_context = context_tensor_0\n",
    "        current_edges = edge_tensor_0\n",
    "        \n",
    "        for layer in range(1, num_layers):\n",
    "            print(f\"\\nLayer {layer}: Abstracting from previous layer\")\n",
    "            \n",
    "            next_context = self.abstract_layer(current_context, current_edges)\n",
    "            \n",
    "            if next_context is None or next_context.shape[0] < 2:\n",
    "                print(f\"  Termination: Not enough vertices for further abstraction\")\n",
    "                break\n",
    "                \n",
    "            next_similarity = self.compute_similarity_matrix(next_context)\n",
    "            next_edges = self.build_edge_tensor(next_context, next_similarity)\n",
    "            \n",
    "            layers.append({\n",
    "                'context': next_context,\n",
    "                'similarity': next_similarity,\n",
    "                'edges': next_edges\n",
    "            })\n",
    "            \n",
    "            print(f\"  Context tensor shape: {next_context.shape}\")\n",
    "            print(f\"  Non-zero edges: {(next_edges[:, :, 0] > 0).sum().item()}\")\n",
    "            \n",
    "            current_context = next_context\n",
    "            current_edges = next_edges\n",
    "        \n",
    "        return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo execution\n",
    "def run_demo():\n",
    "    # Initialize cortex\n",
    "    cortex = CortexTensorDemo(n_basis=8, m_registers=6, b_bits=4, tau=0.5)\n",
    "    \n",
    "    # Create 2 random input HLLSets\n",
    "    input_hllsets = [\n",
    "        torch.bernoulli(torch.ones(6, 4) * 0.4),  # HLLSet A\n",
    "        torch.bernoulli(torch.ones(6, 4) * 0.6)   # HLLSet B\n",
    "    ]\n",
    "    \n",
    "    print(\"Input HLLSet A:\")\n",
    "    print(input_hllsets[0])\n",
    "    print(\"\\nInput HLLSet B:\")\n",
    "    print(input_hllsets[1])\n",
    "    \n",
    "    # Run cortex transformation\n",
    "    layers = cortex.cortex_transformation(input_hllsets, num_layers=3)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n=== Results Summary ===\")\n",
    "    for i, layer in enumerate(layers):\n",
    "        print(f\"Layer {i}:\")\n",
    "        print(f\"  Vertices: {layer['context'].shape[0]}\")\n",
    "        print(f\"  Edges: {(layer['edges'][:, :, 0] > 0).sum().item()}\")\n",
    "        print(f\"  Avg similarity: {layer['similarity'].mean():.3f}\")\n",
    "        \n",
    "        # Show some edge details\n",
    "        edge_mask = layer['edges'][:, :, 0] > 0\n",
    "        if edge_mask.any():\n",
    "            edge_indices = torch.nonzero(edge_mask)\n",
    "            print(f\"  Sample edges: {edge_indices[:3].tolist()}\")\n",
    "    \n",
    "    print(f\"\\nContent store entries: {len(cortex.content_store)}\")\n",
    "    \n",
    "    return cortex, layers\n",
    "\n",
    "# # Run the demo\n",
    "# if __name__ == \"__main__\":\n",
    "#     cortex, layers = run_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input HLLSet A:\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 1., 1., 0.]])\n",
      "\n",
      "Input HLLSet B:\n",
      "tensor([[1., 1., 1., 0.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 0., 1., 1.]])\n",
      "=== Cortex Tensor Demo ===\n",
      "\n",
      "Layer 0: Processing 2 input HLLSets\n",
      "  Context tensor shape: torch.Size([2, 8])\n",
      "  Non-zero edges: 1\n",
      "\n",
      "Layer 1: Abstracting from previous layer\n",
      "  Termination: Not enough vertices for further abstraction\n",
      "\n",
      "=== Results Summary ===\n",
      "Layer 0:\n",
      "  Vertices: 2\n",
      "  Edges: 1\n",
      "  Avg similarity: 0.833\n",
      "  Sample edges: [[0, 1]]\n",
      "\n",
      "Content store entries: 1\n"
     ]
    }
   ],
   "source": [
    "cortex, layers = run_demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
