{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def call_hdf5():\n",
    "    try:\n",
    "        # Make a GET request to the hdf5 service\n",
    "        response = requests.get(\"http://localhost:5000/read\")  # Replace \"/endpoint\" with the actual endpoint of your Flask app\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            return {\"status\": \"success\", \"data\": response.json()}\n",
    "        else:\n",
    "            return {\"status\": \"error\", \"message\": f\"HTTP {response.status_code}: {response.text}\"}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(call_hdf5())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module from sgs_core\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the sgs_core directory to the Python path\n",
    "sys.path.append(str(Path.cwd() / \"sgs_core\"))\n",
    "\n",
    "# Import the meta_algebra module\n",
    "import meta_algebra as md\n",
    "import meta_redis as rs\n",
    "\n",
    "hll1 = md.HllSet(6)\n",
    "hll2 = md.HllSet(6)\n",
    "\n",
    "hll1.add(\"apple\")\n",
    "hll1.add(\"banana\")\n",
    "hll1.add(\"cherry\")\n",
    "\n",
    "hll2.add(\"banana\")\n",
    "hll2.add(\"date\")\n",
    "hll2.add(\"elderberry\")\n",
    "\n",
    "# Perform union and intersection\n",
    "result_union = hll1.union(hll2)\n",
    "result_intersection = hll1.intersection(hll2)\n",
    "\n",
    "print(\"Union:\", result_union.count())\n",
    "print(\"Intersection:\", result_intersection.count())\n",
    "\n",
    "complement = hll1.complement(hll2)\n",
    "print(\"Complement:\", complement.count())\n",
    "d, r, n = hll1.difference(hll2)\n",
    "print(\"Difference:\", d.count(), r.count(), n.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hll3 = md.HllSet(6)\n",
    "hll2.to_binary_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data: str) -> list:\n",
    "    \"\"\"\n",
    "    Simple tokenizer function to split data into tokens.\n",
    "    Args:\n",
    "        data: Input string to tokenize.\n",
    "    Returns:\n",
    "        List of tokens.\n",
    "    \"\"\"\n",
    "    return data.split()\n",
    "\n",
    "meta_redis = rs.RedisStore(host=\"localhost\", port=6379)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def main():\n",
    "# Initialize RedisStore\n",
    "# redis_store = RedisStore(host=\"localhost\", port=6379, db=0)\n",
    "\n",
    "# Sample data for location and dataset\n",
    "location_data = \"New York San Francisco Los Angeles\"\n",
    "dataset_data = \"Temperature Humidity Pressure\"\n",
    "\n",
    "# Tokenize the data\n",
    "location_tokens = tokenize_data(location_data)\n",
    "dataset_tokens = tokenize_data(dataset_data)\n",
    "\n",
    "print(\"Location Tokens:\", location_tokens)\n",
    "print(\"Dataset Tokens:\", dataset_tokens)\n",
    "\n",
    "# Optional batch ID\n",
    "# batch_id = \"batch_001\"\n",
    "\n",
    "# Call the ingest function\n",
    "try:\n",
    "    loc_key, dataset_key = meta_redis.ingest(location_tokens, dataset_tokens)\n",
    "    print(f\"Location Key: {loc_key}\")\n",
    "    print(f\"Dataset Key: {dataset_key}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during ingestion: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"sk-<...>\", base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"Привет, как дела?\"},\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
